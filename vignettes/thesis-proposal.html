
                <!DOCTYPE html>
                <html>
                <head><title>A rough sketch of a BPhil thesis.</title>
                <meta charset="utf-8" />
                <meta content='width=device-width,initial-scale=1' name='viewport' /> 

                <link href='thesis-proposal.css' rel='stylesheet' type='text/css' /> 
                </head>
                <body>
                <header>
                    <h2><a href="../index.html">La Vignetterie.</a></h2>
                </header>
                <main>
                <h1>A rough sketch of a BPhil thesis.</h1>

<!-- l. 7 --><p class='noindent'><span class='ec-lmcsc-10'>very brief abstract. </span>Philosophers and linguists have appealed to computational
and statistical learning theory in debates about the nature of knowledge of language
and language itself, concerning innateness, universal grammar, and the poverty of the
stimulus. (1) Existing learning-theoretic frameworks justifying these arguments must
be read as idealisations. (2) In the light of considerations from the philosophy of
idealisation, it seems that they are often not very good idealisations. They make the
learnability of language more sensitive to minor changes to linguistic stimulus
and requirements on learning than is plausible. (3) But the flaws in these
idealisations can be corrected. I propose to examine what conclusions we can
draw about knowledge of language from more careful appeals to learning
theory.
</p>     
<blockquote class='quote'>
<!-- l. 10 --><p class='noindent'>First come I. My name is Jowett.<br class='newline' />There is no knowledge, but I know it.<br class='newline' />I am Master of this College.<br class='newline' />What I don’t know isn’t knowledge.</p></blockquote>



<!-- l. 16 --><p class='indent'>   The following principles, loosely stated, may seem almost to be nostrums. (1)
Whatever language is, whatever it is to know language, and whatever it
is to learn a language does not preclude our learning it as children. (2) A
(philosophical, scientific,…) theory of language is <span class='ec-lmri-10'>ceteris paribus </span>worse if it
suggests that language acquisition would be <span class='ec-lmri-10'>too hard </span>to be accomplished, and,
conversely, is <span class='ec-lmri-10'>ceteris paribus </span>better if it suggests that language acquisition is
feasible.
</p><!-- l. 19 --><p class='indent'>   <span class='ec-lmr-9'>Aside: It may be legitimate to idealise in a way that suggests we cannot learn language,
if the purpose of the idealisation is to come to understand linguistic phenomena other than
acquisition.</span>
</p><!-- l. 22 --><p class='indent'>   I propose to examine the literature in philosophy, linguistics, and cognitive science
that concerns arguments of the following form (<a id='x1-2'></a><a id='page.3'></a><a href='thesis-proposal.html#X0-nowak2001'><span class='ec-lmcsc-10'>Nowak</span>, <span class='ec-lmcsc-10'>Komarova</span>, and <span class='ec-lmcsc-10'>Niyogi</span></a>,
p. 114).
</p>     
<blockquote class='quote'>
<!-- l. 24 --><p class='noindent'>Children  have  to  deduce  the  rules  of  their  native  language  from
sample sentences they receive from their parents and others. This
information is insufficient for uniquely determining the underlying
grammatical principles. Linguists call this phenomenon the ‘poverty
of stimulus’ or the ‘paradox of language acquisition’. The proposed
solution is universal grammar.</p></blockquote>
<!-- l. 27 --><p class='indent'>   This literature develops from two sources: first, <a id='x1-3'></a><a href='thesis-proposal.html#X0-chomsky1986'><span class='ec-lmcsc-10'>Chomsky</span></a>’s work on poverty of
the stimulus; and, second, formal approaches from theoretical computer science to
developing that argument (also beginning with the formal work of<a id='x1-4'></a> <a href='thesis-proposal.html#X0-gold1967'><span class='ec-lmcsc-10'>Gold</span></a>,
and later marshalled into the Chomskyan tradition). Some (e.g. <a href='thesis-proposal.html#X0-nowak2001'><span class='ec-lmcsc-10'>Nowak</span>,
<span class='ec-lmcsc-10'>Komarova</span>, and <span class='ec-lmcsc-10'>Niyogi</span></a>) argue in favour of universal grammar, others
(e.g.<a id='x1-5'></a> <span class='ec-lmcsc-10'>Clark </span>and <span class='ec-lmcsc-10'>Lappin</span>, <a href='thesis-proposal.html#X0-clark2010'>“Grammar”</a><a id='x1-6'></a>, <a href='thesis-proposal.html#X0-clark2011'><span class='ec-lmri-10'>Nativism</span></a><a id='x1-7'></a>, <a href='thesis-proposal.html#X0-clark2012'>“Theory”</a><a id='x1-8'></a>, <a href='thesis-proposal.html#X0-clark2013'>“Acquisition”</a>)
against.
</p><!-- l. 29 --><p class='indent'>   I propose to identify underlying idealising assumptions common to all sides in this
literature that follow from their borrowing arguments from theoretical computer
science. Following common practice in computer science and engineering, what
counts as too hard is defined in the usual terms of computer science, and
so with respect to inputs of unbounded size. For example, given a list of
<!-- l. 29 --><math display='inline' xmlns='http://www.w3.org/1998/Math/MathML'><mrow><mi>n</mi></mrow></math> elements, as
a function of <!-- l. 29 --><math display='inline' xmlns='http://www.w3.org/1998/Math/MathML'><mrow><mi>n</mi></mrow></math>,
how many comparisons and swaps are needed to sort it? Similarly, given a grammar
of a certain size, as a function of that size, how many linguistic stimuli are needed to
learn it? What if a certain (arbitrarily small) rate of error or risk of failure to learn is
permitted? And how much computation, given those linguistic stimuli, is
necessary?
</p><!-- l. 31 --><p class='indent'>   Considered as idealisations, formal approaches’ principal purpose is to accurately
reflect the structural relations and tradeoffs between different features of
language acquisition (close to the ‘minimal idealisation’ of<a id='x1-9'></a> <a href='thesis-proposal.html#X0-weisberg2007'><span class='ec-lmcsc-10'>Weisberg</span></a>): cognitive
difficulty, the rate of linguistic error, the availability of corrective linguistic



stimulus, and so on. I shall argue that a considerable number of existing
approaches, in this respect, are flawed; learnability results are too sensitive to
what are <span class='ec-lmri-10'>prima facie </span>unimportant features, and so are poor idealisations.
This can be attributed to the habit, borrowed somewhat uncritically from
computer science, of defining difficulty with respect to inputs of unbounded
size.
</p><!-- l. 33 --><p class='indent'>   That argument suggests a subtler understanding of the results from theoretical
computer science on which they rely. I propose therefore in the later part of my
thesis to examine what a different approach to formal idealisations about
language acquisition might suggest about knowledge of language and language
itself.
</p>   
<dl class='thebibliography'><dt class='thebibliography' id='X0-chomsky1986'>
</dt><dd class='thebibliography' id='bib-1'>   
<!-- l. 35 --><p class='noindent'><a id='page.4'></a><a href='thesis-proposal.html' id='X0-'></a><span class='ec-lmcsc-10'>Chomsky</span>,  Noam.  <span class='ec-lmri-10'>Knowledge  of  language:  its  nature,  origin,  and  use</span>.
Convergence. New York: Praeger, 1986. <span class='ec-lmcsc-10'>isbn</span>: 978-0-275-90025-0.
</p>   
</dd>
<dt class='thebibliography' id='X0-clark2010'>
</dt><dd class='thebibliography' id='bib-2'>   
<!-- l. 35 --><p class='noindent'><span class='ec-lmcsc-10'>Clark</span>,  Alexander  and  Shalom  <span class='ec-lmcsc-10'>Lappin</span>.  “Unsupervised  Learning  and
Grammar Induction”. In: <span class='ec-lmri-10'>The Handbook of Computational Linguistics and
Natural Language Processing</span>. John Wiley &amp; Sons, Ltd, 2010, pp. 197–220.
<span class='ec-lmcsc-10'>isbn</span>: 978-1-4443-2404-4. <span class='ec-lmcsc-10'>doi</span>:  <a href='https://doi.org/10.1002/9781444324044.ch8'>10.1002/9781444324044.ch8</a>.
</p>   
</dd>
<dt class='thebibliography' id='X0-clark2011'>
</dt><dd class='thebibliography' id='bib-3'>   
<!-- l. 35 --><p class='noindent'>—   <span class='ec-lmri-10'>Linguistic nativism and the poverty of the stimulus</span>. Chichester, West
Sussex   Malden,   MA:   Wiley-Blackwell,   2011.   <span class='ec-lmcsc-10'>isbn</span>:   978-1-4051-8784-8
978-1-4443-9056-8 978-1-4443-9054-4 978-1-283-51427-9 978-1-4051-8785-5.
<span class='ec-lmcsc-10'>doi</span>:  <a href='https://doi.org/10.1002/9781444390568'>10.1002/9781444390568</a>.
</p>   
</dd>
<dt class='thebibliography' id='X0-clark2012'>
</dt><dd class='thebibliography' id='bib-4'>   
<!-- l. 35 --><p class='noindent'>—   “Computational
Learning Theory and Language Acquisition”. In: <span class='ec-lmri-10'>Philosophy of Linguistics</span>.
Ed. by Ruth <span class='ec-lmcsc-10'>Kempson</span>, Tim <span class='ec-lmcsc-10'>Fernando</span>, and Nicholas <span class='ec-lmcsc-10'>Asher</span>. Handbook
of  the  Philosophy  of  Science.  Amsterdam:  North-Holland,  01/01/2012,
pp. 445–475. <span class='ec-lmcsc-10'>doi</span>:  <a href='https://doi.org/10.1016/B978-0-444-51747-0.50013-5'>10.1016/B978-0-444-51747-0.50013-5</a>.
</p>   
</dd>
<dt class='thebibliography' id='X0-clark2013'>
</dt><dd class='thebibliography' id='bib-5'>   
<!-- l. 35 --><p class='noindent'>—   “Complexity in Language Acquisition”. In: <span class='ec-lmri-10'>Topics in Cognitive Science</span>
5.1 (2013), pp. 89–110. <span class='ec-lmcsc-10'>issn</span>: 1756-8765. <span class='ec-lmcsc-10'>doi</span>:  <a href='https://doi.org/10.1111/tops.12001'>10.1111/tops.12001</a>.
</p>   
</dd>
<dt class='thebibliography' id='X0-gold1967'>
</dt><dd class='thebibliography' id='bib-6'>   
<!-- l. 35 --><p class='noindent'><span class='ec-lmcsc-10'>Gold</span>, E Mark. “Language identification in the limit”. In: <span class='ec-lmri-10'>Information and
Control     </span>10.5     (1967),     pp. 447–474.     <span class='ec-lmcsc-10'>issn</span>:     0019-9958.     <span class='ec-lmcsc-10'>doi</span>:
<a href='https://doi.org/10.1016/S0019-9958(67)91165-5'>10.1016/S0019-9958(67)91165-5</a>.
</p>   
</dd>
<dt class='thebibliography' id='X0-nowak2001'>
</dt><dd class='thebibliography' id='bib-7'>



<!-- l. 35 --><p class='noindent'><span class='ec-lmcsc-10'>Nowak</span>, Martin A., Natalia L. <span class='ec-lmcsc-10'>Komarova</span>, and Partha <span class='ec-lmcsc-10'>Niyogi</span>. “Evolution
of Universal Grammar”. In: <span class='ec-lmri-10'>Science </span>291.5501 (01/05/2001), pp. 114–118.
<span class='ec-lmcsc-10'>doi</span>:  <a href='https://doi.org/10.1126/science.291.5501.114'>10.1126/science.291.5501.114</a>.
</p>   
</dd>
<dt class='thebibliography' id='X0-weisberg2007'>
</dt><dd class='thebibliography' id='bib-8'>   
<!-- l. 35 --><p class='noindent'><span class='ec-lmcsc-10'>Weisberg</span>,  Michael.  “Three  Kinds  of  Idealization”.  In:  <span class='ec-lmri-10'>The  Journal  of
Philosophy </span>104.12 (2007), pp. 639–659. <span class='ec-lmcsc-10'>issn</span>: 0022-362X. JSTOR: <a href='http://www.jstor.org/stable/20620065'>20620065</a>.
<span class='ec-lmcsc-10'>url</span>: <a class='url' href='https://www.jstor.org/stable/20620065'><span class='ec-lmcsc-10'>https://www.jstor.org/stable/20620065</span></a>.</p></dd></dl>


                <h2>À propos.</h2>
                <p>Étiquettes : <a href='../etiquettes/philo.html'>philo</a>, <a href='../etiquettes/linguistics.html'>linguistics</a>, <a href='../etiquettes/chomsky.html'>Chomsky</a>, <a href='../etiquettes/learning-theory.html'>learning theory</a>, <a href='../etiquettes/poverty-of-stimulus.html'>poverty of stimulus</a>, <a href='../etiquettes/nativism.html'>nativism</a>, <a href='../etiquettes/empiricism.html'>empiricism</a>, <a href='../etiquettes/rationalism.html'>rationalism</a>, <a href='../etiquettes/en-cours.html'>en cours</a>, <a href='../etiquettes/vulgarisation.html'>vulgarisation</a>.</p>
                <p>Dernière mise à jour : 16.51 temps universel coordonné 9 June 2025.</p>
                </main>
                </body>
                </html>